# Default values for trading-system helm chart
global:
  imageRegistry: us-central1-docker.pkg.dev
  projectId: sapphireinfinite
  imagePullPolicy: Always

# TPU configuration - enables TPU acceleration for AI agents (cost-effective alternative to GPUs)
# NOTE: TPU quota required - more affordable than GPUs for AI workloads
tpu:
  enabled: false  # Set to true after TPU quota approval
  type: "v5e-lite-podslice"  # Most cost-effective TPU for inference
  machineType: "ct5lp-hightpu-1t"  # TPU v5e instance
  # TPU v5e pricing: ~$1.20/hour vs L4 GPU ~$1.50/hour
  # Performance: 197 TFLOPS optimized for transformer inference

# Redis configuration
redis:
  enabled: true
  architecture: standalone
  auth:
    enabled: false
  master:
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi
  replica:
    replicaCount: 1
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 512Mi
  metrics:
    enabled: true
  persistence:
    enabled: true
    size: 8Gi
  redisConfig:
    maxmemory: "512mb"
    maxmemory-policy: "allkeys-lru"
    tcp-keepalive: "60"
    timeout: "300"
    databases: "16"
    appendonly: "yes"
    appendfsync: "everysec"

# Cloud Trader API Service
cloudTrader:
  enabled: true
  replicaCount: 2
  image:
    repository: cloud-run-source-deploy/cloud-trader
    tag: "latest"
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
  env:
    - name: ENABLE_PAPER_TRADING
      value: "true"
    - name: LOG_LEVEL
      value: "WARNING"
    - name: MCP_ENABLED
      value: "true"
    - name: TELEGRAM_BOT_TOKEN
      value: ""  # Will be overridden by secret
    - name: TELEGRAM_CHAT_ID
      value: ""  # Will be overridden by secret

# MCP Coordinator Service
mcpCoordinator:
  enabled: true
  replicaCount: 1
  image:
    repository: cloud-run-source-deploy/cloud-trader
    tag: "latest"
  service:
    type: ClusterIP
    port: 8081
  resources:
    requests:
      cpu: 200m  # Optimized for message routing
      memory: 512Mi  # Increased for message buffering
    limits:
      cpu: 1000m  # Higher CPU for concurrent processing
      memory: 2Gi
  env:
    - name: LOG_LEVEL
      value: "INFO"
    - name: MCP_ENABLED
      value: "true"
    - name: MESSAGE_COMPRESSION
      value: "true"  # Enable message compression
    - name: CONNECTION_POOL_SIZE
      value: "50"  # Larger connection pool
    - name: MESSAGE_BATCH_SIZE
      value: "100"  # Batch message processing
    - name: ASYNC_WORKERS
      value: "16"  # Concurrent message handlers
    - name: MEMORY_CACHE_ENABLED
      value: "true"  # Enable in-memory caching

# LLM Agent Services
agents:
  enabled: true

  # DeepSeek Agent
  deepseek:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/cloud-trader
      tag: "latest"
    resources:
      requests:
        cpu: 1000m
        memory: 4Gi
      limits:
        cpu: 3000m
        memory: 12Gi
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: ENABLED_AGENTS
        value: '["deepseek-v3"]'
      - name: ENABLE_VERTEX_AI
        value: "true"
      - name: MCP_ENABLED
        value: "true"
      - name: DEEPSEEK_VERTEX_ENDPOINT
        value: "https://us-central1-aiplatform.googleapis.com/v1/projects/sapphireinfinite/locations/us-central1/endpoints/deepseek-momentum-endpoint"
      - name: MODEL_QUANTIZATION
        value: "4bit"  # Enable 4-bit quantization
      - name: GPU_MEMORY_FRACTION
        value: "0.7"  # Use 70% of GPU memory
      - name: INFERENCE_BATCH_SIZE
        value: "8"  # Batch processing for efficiency
      - name: CUDA_LAUNCH_BLOCKING
        value: "0"  # Async CUDA operations

  # Qwen Agent
  qwen:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/cloud-trader
      tag: "latest"
    resources:
      requests:
        cpu: 500m
        memory: 2Gi  # Optimized for quantized models
        nvidia.com/gpu: 1
      limits:
        cpu: 2000m
        memory: 8Gi  # Reduced with quantization
        nvidia.com/gpu: 1
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: ENABLED_AGENTS
        value: '["qwen-adaptive"]'
      - name: ENABLE_VERTEX_AI
        value: "true"
      - name: MCP_ENABLED
        value: "true"
      - name: QWEN_VERTEX_ENDPOINT
        value: "https://us-central1-aiplatform.googleapis.com/v1/projects/sapphireinfinite/locations/us-central1/endpoints/qwen-adaptive-endpoint"
      - name: MODEL_QUANTIZATION
        value: "4bit"
      - name: GPU_MEMORY_FRACTION
        value: "0.8"  # Increased for L4 GPUs
      - name: INFERENCE_BATCH_SIZE
        value: "16"   # Optimized for L4 parallel processing
      - name: CUDA_LAUNCH_BLOCKING
        value: "0"
      - name: TORCH_USE_CUDA_DSA
        value: "1"    # Enable CUDA device-side assertions
      - name: CUDA_VISIBLE_DEVICES
        value: "0"    # Use first GPU
      - name: PYTORCH_CUDA_ALLOC_CONF
        value: "max_split_size_mb:512"  # Optimize memory allocation

  # FinGPT Agent
  fingpt:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/cloud-trader
      tag: "latest"
    resources:
      requests:
        cpu: 1000m
        memory: 4Gi
      limits:
        cpu: 3000m
        memory: 12Gi
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: ENABLED_AGENTS
        value: '["fingpt-alpha"]'
      - name: ENABLE_VERTEX_AI
        value: "true"
      - name: MCP_ENABLED
        value: "true"
      - name: FINGPT_VERTEX_ENDPOINT
        value: "https://us-central1-aiplatform.googleapis.com/v1/projects/sapphireinfinite/locations/us-central1/endpoints/fingpt-alpha-endpoint"
        value: "true"
      - name: MODEL_QUANTIZATION
        value: "4bit"
      - name: GPU_MEMORY_FRACTION
        value: "0.8"  # Increased for L4 GPUs
      - name: INFERENCE_BATCH_SIZE
        value: "16"   # Optimized for L4 parallel processing
      - name: CUDA_LAUNCH_BLOCKING
        value: "0"
      - name: TORCH_USE_CUDA_DSA
        value: "1"    # Enable CUDA device-side assertions
      - name: CUDA_VISIBLE_DEVICES
        value: "0"    # Use first GPU
      - name: PYTORCH_CUDA_ALLOC_CONF
        value: "max_split_size_mb:512"  # Optimize memory allocation

  # Lag-LLaMA Agent
  lagllama:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/cloud-trader
      tag: "latest"
    resources:
      requests:
        cpu: 1000m
        memory: 4Gi
      limits:
        cpu: 3000m
        memory: 12Gi
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: ENABLED_AGENTS
        value: '["lagllama-degen"]'
      - name: ENABLE_VERTEX_AI
        value: "true"
      - name: MCP_ENABLED
        value: "true"
      - name: LAGLLAMA_VERTEX_ENDPOINT
        value: "https://us-central1-aiplatform.googleapis.com/v1/projects/sapphireinfinite/locations/us-central1/endpoints/lagllama-degen-endpoint"
        value: "true"
      - name: MODEL_QUANTIZATION
        value: "4bit"
      - name: GPU_MEMORY_FRACTION
        value: "0.8"  # Increased for L4 GPUs
      - name: INFERENCE_BATCH_SIZE
        value: "16"   # Optimized for L4 parallel processing
      - name: CUDA_LAUNCH_BLOCKING
        value: "0"
      - name: TORCH_USE_CUDA_DSA
        value: "1"    # Enable CUDA device-side assertions
      - name: CUDA_VISIBLE_DEVICES
        value: "0"    # Use first GPU
      - name: PYTORCH_CUDA_ALLOC_CONF
        value: "max_split_size_mb:512"  # Optimize memory allocation

  # VPIN Agent (TPU-accelerated with elastic scaling and fallback - cost-optimized)
  vpin:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/cloud-trader
      tag: "latest"
    resources:
      requests:
        cpu: 1000m
        memory: 4Gi
        google.com/tpu: "1"  # TPU resource instead of GPU
      limits:
        cpu: 3000m
        memory: 12Gi
        google.com/tpu: "1"  # TPU resource instead of GPU
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: ENABLED_AGENTS
        value: '["vpin-hft"]'
      - name: ENABLE_VERTEX_AI
        value: "true"
      - name: MCP_ENABLED
        value: "true"
      - name: VPIN_VERTEX_ENDPOINT
        value: "https://us-central1-aiplatform.googleapis.com/v1/projects/sapphireinfinite/locations/us-central1/endpoints/vpin-hft-endpoint"
      - name: MODEL_QUANTIZATION
        value: "4bit"
      - name: TPU_IP_ADDRESS
        value: ""  # Will be set by TPU runtime
      - name: TPU_NAME
        value: "vpin-tpu"  # TPU instance name
      - name: USE_TPU
        value: "true"  # Enable TPU mode instead of GPU
      - name: XRT_TPU_CONFIG
        value: "localservice;0;localhost:51011"  # TPU runtime config
      - name: INFERENCE_BATCH_SIZE
        value: "32"   # TPU optimized batch size (larger than GPU)
      - name: TPU_PROFILER_PORT
        value: "8466"  # TPU profiling port
      # Elastic scaling and fallback configuration
      - name: ELASTIC_SCALING_ENABLED
        value: "true"
      - name: FALLBACK_MODELS
        value: '["deepseek-v3", "qwen-adaptive", "fingpt-alpha"]'
      - name: API_THROTTLE_DETECTION_ENABLED
        value: "true"
      - name: THROTTLE_THRESHOLD_REQUESTS
        value: "10"  # Requests per minute threshold
      - name: THROTTLE_BACKOFF_SECONDS
        value: "300"  # 5 minutes backoff when throttled
      - name: RESOURCE_CONSERVATION_MODE
        value: "true"  # Scale down when throttled
      - name: FALLBACK_ACCURACY_THRESHOLD
        value: "0.85"  # Minimum acceptable accuracy for fallback models

# Trading Framework Services
frameworks:
  enabled: true

  # Freqtrade HFT
  freqtrade:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/freqtrade
      tag: "latest"
    resources:
      requests:
        cpu: 750m  # Optimized for vectorized operations
        memory: 1.5Gi  # Reduced with memory optimization
      limits:
        cpu: 3000m  # Increased for parallel processing
        memory: 6Gi
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: FREQTRADE__EXCHANGE__NAME
        value: "asterdex"
      - name: FREQTRADE__TELEGRAM__ENABLED
        value: "true"
      - name: NUMBA_THREADING_LAYER
        value: "omp"  # Optimize Numba threading
      - name: OMP_NUM_THREADS
        value: "4"  # Parallel computation threads
      - name: PYTHONOPTIMIZE
        value: "1"  # Enable Python optimizations
      - name: VECTORIZE_OPERATIONS
        value: "true"  # Enable SIMD vectorization

  # Hummingbot Market Maker
  hummingbot:
    enabled: true
    replicaCount: 1
    image:
      repository: cloud-run-source-deploy/hummingbot
      tag: "latest"
    resources:
      requests:
        cpu: 500m  # Optimized resource usage
        memory: 1Gi  # Increased for market data caching
      limits:
        cpu: 2000m
        memory: 4Gi
    env:
      - name: ENABLE_PAPER_TRADING
        value: "true"
      - name: HUMMINGBOT__TELEGRAM__ENABLED
        value: "true"
      - name: ASYNC_IO_WORKERS
        value: "8"  # Optimize async I/O
      - name: CONNECTION_POOL_SIZE
        value: "20"  # Connection pooling
      - name: MEMORY_CACHE_SIZE
        value: "512MB"  # In-memory cache size
      - name: NETWORK_TIMEOUT
        value: "5"  # Reduced network timeout

# Horizontal Pod Autoscaling
hpa:
  enabled: true

  # VPIN HPA (Elastic scaling with intelligent resource management)
  vpin:
    enabled: true
    minReplicas: 0  # Can scale to zero when throttled
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60  # Lower threshold for GPU workloads
    targetMemoryUtilizationPercentage: 75
    # Custom metrics for intelligent scaling
    customMetrics:
      - type: Pods
        pods:
          metric:
            name: api_requests_per_second
          target:
            type: AverageValue
            averageValue: 5  # Scale up if >5 req/sec
      - type: Pods
        pods:
          metric:
            name: throttle_rate
          target:
            type: AverageValue
            averageValue: 0.1  # Scale down if throttle rate >10%

  # Freqtrade HPA
  freqtrade:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

  # Hummingbot HPA
  hummingbot:
    enabled: true
    minReplicas: 1
    maxReplicas: 2
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

# Service Account for GCP access
serviceAccount:
  create: true
  name: trading-system-sa
  annotations:
    iam.gke.io/gcp-service-account: trading-system@sapphireinfinite.iam.gserviceaccount.com

# Security Context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 2000

# Node Selector for TPU nodes (only used when tpu.enabled=true)
nodeSelector:
  cloud.google.com/gke-tpu-accelerator: v5-lite-podslice
  cloud.google.com/gke-tpu-topology: "1"
  instance-type: ct5lp-hightpu-1t

# Tolerations for TPU workloads (only used when tpu.enabled=true)
tolerations:
  - key: "google.com/tpu"
    operator: "Exists"
    effect: "NoSchedule"

# Affinity rules
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - cloud-trader
            - freqtrade-hft
            - hummingbot-mm
        topologyKey: kubernetes.io/hostname

# System Initialization Job
systemInitialization:
  enabled: true
  image:
    repository: cloud-run-source-deploy/cloud-trader
    tag: "latest"
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
