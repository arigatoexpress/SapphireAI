version: "3.9"

services:
  vllm-server:
    build: .
    image: atlas/vllm-server:latest
    container_name: vllm-server
    restart: unless-stopped
    environment:
      MODEL_PATH: ${MODEL_PATH:-/models}
      TOKENIZER_PATH: ${TOKENIZER_PATH:-}
      HF_MODEL_ID: ${HF_MODEL_ID:-}
      HOST_PORT: ${HOST_PORT:-8081}
      MAX_NUM_BCT: ${MAX_NUM_BCT:-8192}
      GPU_MEMORY_UTILIZATION: ${GPU_MEMORY_UTILIZATION:-0.9}
      VLLM_ARGS: ${VLLM_ARGS:-}
    volumes:
      - ${MODEL_DIR:-./models}:/models:ro
    ports:
      - "${HOST_PORT:-8081}:8081"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia

